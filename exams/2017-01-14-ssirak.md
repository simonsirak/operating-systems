# 1
## 1.1
För denna fil kan kalle skriva, läsa och exekvera filen. Alla i gruppen trusted kan läsa och exekvera filen, men inte skriva till den. Ingen annan kan skriva, läsa eller exekvera filen.
(2p)

## 1.2
* wc räknar antalet ord i en fil och skriver ut dessa till stdout.
* grep skriver till stdout ut alla förekomster av ett simpelt regex i en fil.
* mkdir skapar en mapp med ett visst namn i nuvarande directory.
* pwd skriver ut en absolut path från root-directory till inuti det directory man befinner sig till stdout.
(2p)

# 2
## 2.1
Forkade processer delar inte globalt minne, stack, kod, ingenting -- bara underliggande file descriptor objekt. Så det kommer 
printas ut "x = 43" två gånger, en per rad (både ursprunget och fork:en har x = 42 när de splittas och inkrementering sker på antingen ena processen eller andra, de delar inte globalt minne).
(2p)

## 2.2 *
IDT:n innehåller för varje interrupt (IO, timer, etc) en pekare till en dedikerad handler-procedur som OS:en har satt upp vid boot. När man exekverar instruktionen INT så kollar OS:en genom interrupt handlern att allt är okej, och skickar sedan till en eventuell handler som processen har specificerat, där man kan göra mer specifik hantering av interrupten.
(1p)

# 3
## 3.1
start går till ready. ready går till running om schedulerad. Running går till ready om avschedulerad. Running går till blocked om IO-operation görs. blocked går tll ready om IO är färdig. Running går till exit om processen är klar.
(2p)

## 3.2
Antar att man tänker i termer av turnaround time. SJF ger (10 + (10 + 20) + (10 + 20 + 30)) / 3 = 33.333333..., random skulle kunna ge 
(30 + (30 + 20) + (30 + 20 + 10)) / 3 = 140 / 3 > 33.3333.., så SJF är bättre i detta fall. SJF är optimal under antagandet att alla jobb kommer samtidigt, längderna är kända och ingen preemption. Och vi har sett att det finns ett fall där random är sämre än optimal, så SJF är garanterat bättre.
(2p)

## 3.3 *
"Stride" scheduling. Varje process har ett antal lotter, och man får ta ett steg framåt som blir kortare ju fler lotter man har, varje gång processen får processorn. Den som har gått "kortast" sträcka får processorn därnäst. Denna ger således proportionerlig processorkraft till antalet lotter.
(0p: Lotter har inget med saken o göra tror jag)

# 4
## 4.1
Om man inte har ett bounds-register kan de addresser som hanteras vid körning av programmet (t.ex skrivning till en viss minnesaddress) inte garanteras vara inom segmentet i fråga. En boundary behövs för att segmentets övre och nedre gräns ska kunna specificeras, så att alla virtuella adresser kan kontrolleras ligga inom gränserna i fråga.
(2p)

## 4.2
En trädstruktur medför att det krävs mindre minne i RAM för datastrukturen. Varje sida i en mapp i trädet lagrar pekare till otroligt många andra sidor (som inte behöver vara i minnet), mer specifikt så många pekare som får plats i en sida. Så alla sidor behöver inte ligga på minnet samtidigt, vilket sparar väldigt mycket minne.
(2p?)

## 4.3 *

# 5
## 5.1
Det första förrlaget är sämst pga intern fragmentering, dvs av den allokerade ytan används inte särskilt mycket. I det andra förslaget så suger den pga extern fragmentering; att dom kan ligga hur tätt intill varandra som helst utan struktur gör att det med tiden bildas små fickor mellan bilar (om det är många bilar som vill parkera), och platsen används då inte effektivt heller. 
(2p)

## 5.2
Vi kan genomföra coalescing, dvs sätta ihop två grannblock så att minnesblocket ses som en helhet. Om man har minnet ordnat så kommer detta vara så enkelt som att kolla på grannelementen, vilket tar konstant tid. Om listan inte är ordnad måste man söka rätt på blocken som ligger innan/efter i listan, vilket kan ta linjär tid.
(2p)

## 5.3 *

# 6
## 6.1
count är en global variabel, vilket innebär att den kan kommas åt mellan trådar. Det största värdet count kan bli är 20 (om man tänker sig att inga data races sker). Det minsta värdet är 1 (om t1 skriver 1, t2 skriver över till 1 igen, osvosv.. när t1 är på sista iterationen skriver den 1 och t2 detsamma). 
(1p)

## 6.2
Sant, de kan läsa från varanddras stackar eftersom trådar delar processens addressrymd.
(2p)

## 6.3 *
vettefan

# 7
## 7.1
Falskt. Zombies är för processer som har avslutats men där förälderprocessen inte hunnit läsa resultatet ännu. Om alla länkar till en fil tas bort så är filen oåtkomlig och tas bort från filsystemet.
(2p)

## 7.2
Bitmappen för inodes används för att beskriva vilka platser i inode-blocken som används. Bitmappen för datablock används för att markera vilka datablock som används.
(2p)

## 7.3 *
En mapp innehåller information om varje directory entry. Varje entry beskriver filnamnet, dess inode-nummer och vilken typ av fil det är. Detta lagras i datablock för mappen, som egentligen är en typ av fil bara. Mappen har en inode, och i den står det mer om vilken typ av fil det är (mapp), rättigheter osv.

# 8
## 8.1
Sant, alla systemanrop och priviligerade operationer redirectas dock till kernel mode på ett kontrollerat sätt fram och tillbaka. 
(1p)

## 8.2 *
vettefan

# 9
## 9.1
Rad 1: code, där binärer ligger. Rad 2: read-only data, där read-only data (t.ex konstanter) kan ligga. Rad 3: Global data, där globala variabler lagras. Rad 4: Heap, där mallocerade variabler ligger. Rad 5: Ett shared library. Rad 6: Stack, där lokala variabler lagras.
(2p)

## 9.2 *
execlp modifierar processen så att den agerar som programmet "gurka". Detta görs för barnprocessen efter fork:en. Så barnprocessen kommer aldrig att printa Humle. När den terminerar komemr dock föräldern skriva ut Dumle.
(2p)

## 9.3 
Vet inte, tror inte det. 

## 9.4 *

## 9.5

## 9.6
Koden flyttar över en entry till slutet av listan, för att hålla listan sorterad över "hur nyligen man använt en viss entry". Koden används varje gång man accessar en sida (som finns i minnet).
(2p)

## 9.7 *

## 9.8
Kan...
(2p)

## 9.9
Kan typ...
(1p)

## 9.10 *

Totalt: 33 grundpoäng. I princip bara implementationsdelen som jag missar på.
