# 1
## 1.1
För denna fil kan kalle skriva, läsa och exekvera filen. Alla i gruppen trusted kan läsa och exekvera filen, men inte skriva till den. Ingen annan kan skriva, läsa eller exekvera filen.

## 1.2
* wc räknar antalet ord i en fil och skriver ut dessa till stdout.
* grep skriver till stdout ut alla förekomster av ett simpelt regex i en fil.
* mkdir skapar en mapp med ett visst namn i nuvarande directory.
* pwd skriver ut en absolut path från root-directory till inuti det directory man befinner sig till stdout.

# 2
## 2.1
Forkade processer delar inte globalt minne, stack, kod, ingenting -- bara underliggande file descriptor objekt. Så det kommer 
printas ut "x = 43" två gånger, en per rad (både ursprunget och fork:en har x = 42 när de splittas och inkrementering sker på antingen ena processen eller andra, de delar inte globalt minne).

## 2.2 *
IDT:n innehåller för varje interrupt (IO, timer, etc) en pekare till en dedikerad handler-procedur som OS:en har satt upp vid boot. När man exekverar instruktionen INT så kollar OS:en genom interrupt handlern att allt är okej, och skickar sedan till en eventuell handler som processen har specificerat, där man kan göra mer specifik hantering av interrupten.

# 3
## 3.1
start går till ready. ready går till running om schedulerad. Running går till ready om avschedulerad. Running går till blocked om IO-operation görs. blocked går tll ready om IO är färdig. Running går till exit om processen är klar.

## 3.2
Antar att man tänker i termer av turnaround time. SJF ger (10 + (10 + 20) + (10 + 20 + 30)) / 3 = 33.333333..., random skulle kunna ge 
(30 + (30 + 20) + (30 + 20 + 10)) / 3 = 140 / 3 > 33.3333.., så SJF är bättre i detta fall. SJF är optimal under antagandet att alla jobb kommer samtidigt, längderna är kända och ingen preemption. Och vi har sett att det finns ett fall där random är sämre än optimal, så SJF är garanterat bättre.

## 3.3 *
"Stride" scheduling. Varje process har ett antal lotter, och man får ta ett steg framåt som blir kortare ju fler lotter man har, varje gång processen får processorn. Den som har gått "kortast" sträcka får processorn därnäst. Denna ger således proportionerlig processorkraft till antalet lotter.

# 4
## 4.1
Om man inte har ett bounds-register kan de addresser som hanteras vid körning av programmet (t.ex skrivning till en viss minnesaddress) inte garanteras vara inom segmentet i fråga. En boundary behövs för att segmentets övre och nedre gräns ska kunna specificeras, så att alla virtuella adresser kan kontrolleras ligga inom gränserna i fråga.

## 4.2
En trädstruktur medför att det krävs mindre minne i RAM för datastrukturen. Varje sida i en mapp i trädet lagrar pekare till otroligt många andra sidor (som inte behöver vara i minnet), mer specifikt så många pekare som får plats i en sida. Så alla sidor behöver inte ligga på minnet samtidigt, vilket sparar väldigt mycket minne.

## 4.3 *

# 5
## 5.1
Det första förrlaget är sämst pga intern fragmentering, dvs av den allokerade ytan används inte särskilt mycket. I det andra förslaget så suger den pga extern fragmentering; att dom kan ligga hur tätt intill varandra som helst utan struktur gör att det med tiden bildas små fickor mellan bilar (om det är många bilar som vill parkera), och platsen används då inte effektivt heller. 

## 5.2
Vi kan genomföra coalescing, dvs sätta ihop två grannblock så att minnesblocket ses som en helhet. Om man har minnet ordnat så kommer detta vara så enkelt som att kolla på grannelementen, vilket tar konstant tid. Om listan inte är ordnad måste man söka rätt på blocken som ligger innan/efter i listan, vilket kan ta linjär tid.

## 5.3 *

# 6
## 6.1

