# 1
## 1.1
Code area and open files. The forked process will get a copy of each file descriptor, but the underlying file objects will be the same. The code is identical between them, and so can be shared as well.

## 1.2
Stack:

```
ESP(foo)

VAL(4)
VAL(3)
EIP(bar:s next low-level instruction)
ESP(bar)
EBP(foo) : EBP(bar)
&z
```

## 1.3
We have forgotten to free the buffer used to generate the fib numbers. If the process repeatedly uses this procedure, then the memory leak will get out of hand.

## 1.4
These languages have a garbage collector routine that executes occasionally. The GC essentially frees any memory that holds an object that is not referenced anywhere. These languages do however have a Stack and a Heap (for instance, "heap-allocation" in Java is done by "new Object()").

## 1.5 *
The system could be implemented using a binary buddy system: When requesting memory of size X, we start by looking at the entire memory, then divide it in half and check the halves recursively. This is done until we find the smallest possible power of two > X (+ some overhead needed for allocation, such as a magic number for the allocated memory). A disadvantage is that this may lead to internal fragmentation since memory is overestimated such that they fit a power of two. 

Freeing is done by marking the block as free. We then check the buddy by checking a certain address. This address is found by flipping the bit that is on an offset corresponding to the recursion depth of the block. If the buddy block (which is of the same size) is also free, coalescing becomes a really fast operation (simply merge the blocks). This is the advantage of having structure in the blocks handed out.

## 1.6 *
We do this to avoid excessive spinning for the entire duration of a time slot on the processor. Yield only wakes up if the scheduler so desires. Futex_wait only wakes the process up if the actual lock has been freed (and the scheduler chooses the specific thread).

# 2
## 2.1
The forked process does not share global memory with the parent process. The parent will count to 10, wait for the child process to count to 10, and then finish by printing out "count = 10".

## 2.2
Third one is true. First is false bc pipe is for 1 direction only. Second is false bc if something has been sent, it will be read in its entirety, but the pipe may buffer input.

## 2.3 *

# 3
## 3.1
Turnaround time is the time from arrival to completion. The average turnaround time of the first strategy is (30 + 60 + 90)/3 = 60 ms. Round-robin would yield an average tunraround time of ((30 + 30 + 10) + (30 + 30 + 20) + (30 + 30 + 30))/3 = 80 ms if we do a simple round-robin (J1-J2-J3-J1-...).

## 3.2
The process can game the OS by issuing an IO operation right before the end of a time slice, causing it to stay high priority even though it is not even actually an interactive process (just fakes it). We can solve this by replacing 4a and 4b with the rule "a job that has used up a total time-allotment in a certain priority is moved to a lower priority". Even if you preempt, the fact that we now keep track of total time makes you unable to game the OS like we did previously.

## 3.3 *
It is the state right before the exit state. A process is in this state after it has finished. It is there so that a parent process can still read the return code. After it is read, the process is moved to the exit state (and is terminated fully).

# 4
## 4.1
input is virtual address. Output is physical address. The offset is what is sent to the upper adder. The virtual page number is what is sent from above into the big rectangle, which is the TLB. The TLB outputs a frame number to the adder. To the right of the lower adder is the page table base register, which is added with the VPN to result in the desired page table address (in the case of a cache miss). The page table is the lower most dotted rectangle. We grab the PTE from there and insert it into the TLB, which we then spit out into the upper adder.

## 4.2
It is hidden in the beginning of the allocated memory. We are hiding the size of the allocated memory. <should prolly revise this...>
  
## 4.3 *

# 5
## 5.1
We would have the first segment be the superblock that would contain information about the file system (size of the different parts of the file system, where each part starts). Then we would have 1 segment for an inode bitmap, and 1 segment for a data bitmap. These would store which other segments/sub-segments of memory are free. Then we would have a number of segments dedicated for inodes (an inode would take up like 128 bytes, i.e not an entire segment). Then lastly a whole bunch of data segments.

## 5.2
Soft links. <idk haha.. Måste läsa kapitlet om filsystem-API igen, samt om memory management>

## 5.3 *
